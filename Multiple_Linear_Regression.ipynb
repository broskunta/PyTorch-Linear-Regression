{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7G9Z9TttiZxrsjvdPj56a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/broskunta/PyTorch-Linear-Regression/blob/main/Multiple_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple Linear Regression\n",
        "Working with multiple inputs."
      ],
      "metadata": {
        "id": "bwymq7V_umGF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparation\n",
        "\n",
        "Import libraries and set the randon seed"
      ],
      "metadata": {
        "id": "1zCIXfWTuyeN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4ywD29At6LC",
        "outputId": "2e596fda-6709-46f2-df9b-fd06201f24e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f3963b33bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#import libraries\n",
        "\n",
        "from torch import nn\n",
        "import torch\n",
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction"
      ],
      "metadata": {
        "id": "8NMFgjizvBjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set the parameters weight and bias\n",
        "\n",
        "w = torch.tensor([[2.0], [3.0]], requires_grad= True)\n",
        "b = torch.tensor([[1.0]], requires_grad= True)"
      ],
      "metadata": {
        "id": "-StXBu_svAR5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the prediction function\n",
        "def forward(x):\n",
        "    yhat = torch.mm(x,w) + b #torch.mm supports matrix multiplication\n",
        "    return yhat"
      ],
      "metadata": {
        "id": "1IBn6mSfvYJK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use the forward function to make a prediction\n",
        "\n",
        "x = torch.tensor([[1.0, 2.0]])\n",
        "yhat = forward(x)\n",
        "print(\"The result is: \", yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3VUJ3PBvls2",
        "outputId": "7096c4de-cb8e-4c3f-9adc-f910c07580b2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The result is:  tensor([[9.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## multiple rows of inputs\n",
        "\n",
        "X = torch.tensor([[1.0, 1.0], [1.0, 2.0], [1.0, 3.0]])"
      ],
      "metadata": {
        "id": "efS72LIXv3Y5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make prediction\n",
        "yhat = forward(X)\n",
        "print(\"The result is: \", yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UdyEBtWwYqA",
        "outputId": "db114953-1bbc-434b-8ead-282d1bdec83e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The result is:  tensor([[ 6.],\n",
            "        [ 9.],\n",
            "        [12.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build Custom Modules"
      ],
      "metadata": {
        "id": "R21pT1Lf5MIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create linear regression\n",
        "class linear_regression(nn.Module):\n",
        "\n",
        "    #constructor\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(linear_regression, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, output_size)\n",
        "\n",
        "    # prediction function\n",
        "    def forward(self, x):\n",
        "        yhat = self.linear(x)\n",
        "        return yhat"
      ],
      "metadata": {
        "id": "ii3iJn6fwfWu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make model\n",
        "model = linear_regression(2,1)"
      ],
      "metadata": {
        "id": "Vnsbc1fa52aW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the parameters\n",
        "print(\"The parameters are: \", list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkuTC6AP6XVi",
        "outputId": "4e261680-f599-4ebe-e066-17ece64afa67"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The parameters are:  [Parameter containing:\n",
            "tensor([[ 0.3643, -0.3121]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.1371], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# another method\n",
        "print(\"The model parameters are: \", model.state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgNNvhzs6iTH",
        "outputId": "75fe6076-77a7-4650-f580-025d9e49c0bb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model parameters are:  OrderedDict([('linear.weight', tensor([[ 0.3643, -0.3121]])), ('linear.bias', tensor([-0.1371]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#make a prediction of x\n",
        "yhat = model(x)\n",
        "print(\"The result is: \", yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWxnsEfu6t2q",
        "outputId": "3d0d1c9c-d082-4029-9a64-6b3c7bd9fade"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The result is:  tensor([[-0.3969]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make prediction of X\n",
        "yhat = model(X)\n",
        "print(\"The result is: \", yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwmsKIQP637w",
        "outputId": "d72070db-053b-43e6-aa23-1a32f2bd29bf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The result is:  tensor([[-0.0848],\n",
            "        [-0.3969],\n",
            "        [-0.7090]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Practise"
      ],
      "metadata": {
        "id": "NlpwuT0K8Flq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Practice: Build a model to predict the follow tensor.\n",
        "\n",
        "X = torch.tensor([[11.0, 12.0, 13, 14], [11, 12, 13, 14]])"
      ],
      "metadata": {
        "id": "C7Hk8dIP77Iz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make model\n",
        "model = linear_regression(4,1)"
      ],
      "metadata": {
        "id": "hUkoRjGJ8TuM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the parameters\n",
        "print(\"The parameters are: \", list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDwNfyc88UvL",
        "outputId": "c48d00cf-7f5a-43ab-a9be-357f41c244e1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The parameters are:  [Parameter containing:\n",
            "tensor([[ 0.2347, -0.4707,  0.2999, -0.1029]], requires_grad=True), Parameter containing:\n",
            "tensor([0.2544], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# another method\n",
        "print(\"The model parameters are: \", model.state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_MhAGM28XUg",
        "outputId": "ce66271b-4441-42fd-d179-e9c1b4c3975e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model parameters are:  OrderedDict([('linear.weight', tensor([[ 0.2347, -0.4707,  0.2999, -0.1029]])), ('linear.bias', tensor([0.2544]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make prediction of X\n",
        "yhat = model(X)\n",
        "print(\"The result is: \", yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuGuk9xY8arc",
        "outputId": "49b36bae-044b-4aa7-9b2b-783a50ce33df"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The result is:  tensor([[-0.3546],\n",
            "        [-0.3546]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_buIccDl8cu1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}